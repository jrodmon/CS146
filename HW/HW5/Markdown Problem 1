1. 
T(N) = 2T(N-1) + 1
Master Theorem for "decreasing" function
a = 2, b = 1, f(n) = 1
T(n) = O(f(n)^k * a^(n/b))
T(n) = O(1^k * 2^n)    
T(n) = O(2^n)      // <--- MASTER THEOREM ANSWER

Algebraic work:
1. T(N) = 2T(N-1) + 1
2. T(N-1) = (2T(N-2) + 1)
3. T(N-2) = 2T(N-3) + 1

T(N) = 2(2(2T(N-3) + 1) + 1) + 1
T(N) = 4(2T(N-3) +2) + 2) + 1
T(N) = 8T((N-3)+4) + 2 + 1
T(N) = 2^3 T(N-3) + 2^2 + 2^1 + 2^0
using k
T(N) = 2^k T(N-k) + 2^(k-1) + 2^(k-2) + ... + 2^1 + 2^0
                    these values are constants, which when scaled to infinity are negligible
let's assume n-k = 0 and T(0) = 1
T(N) = 2^k T(N-k) + C
T(N) = 2^k T(0)
T(N) = 2^k          // <--- algebraically checked answer


2. 
T(N) = 3T(N-1) + n
Master Theorem for "decreasing" function
a = 3, b = 1, f(n) = n
Case 3: a > 1
T(n) = O(n * 3^n)    // <--- MASTER THEOREM ANSWER

Algebraic work
1. T(N) = 3T(N-1) + n
2. T(N-1) = 3T(N-2) + n
3. T(N-2) = 3T(N-3) + n
sub all values into T(N)
T(N) = 3(3(3T(N-3) + n) + n) + n
T(N) = 9(3T(N-3) + 3n) + 3n) + n
T(N) = 27T(N-3) + 9n + 3n + n
T(N) = 3^3T(N-3) + 3^(2)*n + 3^(1)*n + 3^(0)*n
apply k logic
T(N) = 3^kT(N-k) + 3^(k-1)*n + 3^(k-2)*n + ... + 3^1*n + 3^0*n
Assume N-k = 0, and T(0) = 1
N = k
T(N) = 3^kT(0) + 3^(k)*n
T(N) = 3^k*1 + 3^k * n
T(N) = 3^k + 3^k*n
        ^ This value is negligible when scaled to infinity
Θ(3^k * n)             // <--- algebraically checked answer



3. 
T(N) = 9T(N/2) + n^2
divide and conquer function
a = 9, b = 2, f(n) = n^2
Let's calculate n^log_b(a)       
log 9 / log 2 = 3.169 ~ 3.17     // This is the same as n^(log base 2 of 9)
log_b(a) = n^3.17                // where does this stand against f(n)?

n^(3.17 - e) = n^2    //Now we realize this is Case 1
e = 1.17  
T(n) = Θ(f(n)) 
T(n) = Θ(n^2)            // <--- ANSWER

Algebra
T(N) = 9T(N/2) + n^2
T(N/2) = 9T(N/4) + ((n/2)^2)
plugging in
T(N) = 9(9T(N/4) + ((n/2)^2)) + n^2
T(N) = 81T((N/4) + 9((n/2)^2)) + n^2
T(N) = 9^kT((N/4) + 9((n/2)^k + n^2
The dominating element in this is n^2
Therefore 
Θ(N^2)


4. 
T(N) = 100T(N/2) + n^(log_2cn + 1)  (c is a constant) (since c is a constant, we can just call it cn = n for large values)
divide and conquer function
a = 100, b = 2, f(n) = n^(log_2(n) + 1)  n to the power of log base 2 of c*n + 1
Calculate n^(log_b(a))
n^(log_2(100)) = n^6.64
n^(log_2(100) + e)   vs n^(log_2(n) + 1)    
RHS is greater, so we have to add an e to the LHS to keep them equal.
This is CASE 3:
Θ(f(n))
Θ(n^(log_2(n)+1)
Θ(n^(log_2(n)))

Algebraically
    0. T(N) = 100T(N/2) + N^(log_2(cn)+1)
    1. T(N/2) = 100(100T(N/2/2) + (N/2)^(log_2(cn)+1) + N^(log_2(cn)+1)
       T(N/2) = 100^2*T(N/4) + 100(N/2)^(log_2(cn)+1) + N^(log_2(cn)+1)
    2. T(N/4) = 100(100^2*T(N/4/2) + (N/4)^(log_2(cn)+1)) + 100(N/2)^(log_2(cn)+1) + N^(log_2(cn)+1)
       T(N/4) = 100^3*T(N/8) + 100(N/4)^(log_2(cn)+1)) + 100(N/2)^(log_2(cn)+1) + N^(log_2(cn)+1)
The dominating term in this is the final term, "N^(log_2(cn)+1)
Therefore 
Θ(N^(log_2(cn)+1)


5.
T(N) = 4T(N/2) + n^2*logn
a = 4, b = 2, f(n) = n^2*log(n)
n^(log_2(4)) = n^2
n^2 vs n^2*logn
n^2 < n^2*logn
what makes these two values equal?
n^(2 + e) = n^2 * log(n)
the LHS would need some additional e value to be equal to the value of the RHS
therefore
T(n) = Θ(n^2*logn)


Recursion Tree Method



6. 
T(N) = 5T(N/2) + n^(2)/log(n)
a = 5, b = 2, f(n) = n^2 / log(n)
n^(log_2(5)) vs n^2 / log(n)
n^2.32       vs log (n^2 / log(n))
n^2.32       vs 2log(n) - log(log(n))
n^2.32 > 2log(n)
The LHS would need 
T(n) = n^2.32


